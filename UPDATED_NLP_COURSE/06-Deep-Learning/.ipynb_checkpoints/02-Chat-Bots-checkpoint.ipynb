{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'john': 1,\n",
       " 'back': 2,\n",
       " 'dropped': 3,\n",
       " 'sandra': 4,\n",
       " 'is': 5,\n",
       " 'yes': 6,\n",
       " 'kitchen': 7,\n",
       " '?': 8,\n",
       " 'daniel': 9,\n",
       " '.': 10,\n",
       " 'picked': 11,\n",
       " 'moved': 12,\n",
       " 'in': 13,\n",
       " 'journeyed': 14,\n",
       " 'there': 15,\n",
       " 'put': 16,\n",
       " 'got': 17,\n",
       " 'the': 18,\n",
       " 'down': 19,\n",
       " 'garden': 20,\n",
       " 'discarded': 21,\n",
       " 'no': 22,\n",
       " 'left': 23,\n",
       " 'bathroom': 24,\n",
       " 'apple': 25,\n",
       " 'office': 26,\n",
       " 'bedroom': 27,\n",
       " 'football': 28,\n",
       " 'went': 29,\n",
       " 'mary': 30,\n",
       " 'travelled': 31,\n",
       " 'grabbed': 32,\n",
       " 'hallway': 33,\n",
       " 'took': 34,\n",
       " 'milk': 35,\n",
       " 'up': 36,\n",
       " 'to': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 18, 27, 10],\n",
       "       [ 0,  0,  0, ..., 18, 20, 10],\n",
       "       [ 0,  0,  0, ..., 18, 20, 10],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 18, 25, 10],\n",
       "       [ 0,  0,  0, ..., 18, 20, 10],\n",
       "       [ 0,  0,  0, ..., 25, 15, 10]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 13, 18,  7,  8],\n",
       "       [ 5,  1, 13, 18,  7,  8],\n",
       "       [ 5,  1, 13, 18, 20,  8],\n",
       "       ...,\n",
       "       [ 5, 30, 13, 18, 27,  8],\n",
       "       [ 5,  4, 13, 18, 20,  8],\n",
       "       [ 5, 30, 13, 18, 20,  8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 12s 24ms/step - loss: 1.1748 - accuracy: 0.4846 - val_loss: 0.6947 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.7103 - accuracy: 0.5029 - val_loss: 0.6989 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6954 - accuracy: 0.5064 - val_loss: 0.6932 - val_accuracy: 0.5210\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6951 - accuracy: 0.5001 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.6944 - accuracy: 0.5094 - val_loss: 0.6949 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6946 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6954 - accuracy: 0.4901 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6939 - accuracy: 0.5059 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6936 - accuracy: 0.5082 - val_loss: 0.6958 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6954 - accuracy: 0.4960 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6929 - accuracy: 0.5161 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6949 - accuracy: 0.4934 - val_loss: 0.6941 - val_accuracy: 0.4890\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6954 - val_accuracy: 0.4770\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6899 - accuracy: 0.5323 - val_loss: 0.6886 - val_accuracy: 0.5400\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6767 - accuracy: 0.5653 - val_loss: 0.6541 - val_accuracy: 0.6210\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6440 - accuracy: 0.6345 - val_loss: 0.6269 - val_accuracy: 0.6540\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6255 - accuracy: 0.6571 - val_loss: 0.6115 - val_accuracy: 0.68006256 - accuracy: \n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.6064 - accuracy: 0.6860 - val_loss: 0.5975 - val_accuracy: 0.6880\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5858 - accuracy: 0.7005 - val_loss: 0.5624 - val_accuracy: 0.7110\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5633 - accuracy: 0.7202 - val_loss: 0.5289 - val_accuracy: 0.7540\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5377 - accuracy: 0.7466 - val_loss: 0.5069 - val_accuracy: 0.7680\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5280 - accuracy: 0.7474 - val_loss: 0.4927 - val_accuracy: 0.7720\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5035 - accuracy: 0.7679 - val_loss: 0.4775 - val_accuracy: 0.7870\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4899 - accuracy: 0.7727 - val_loss: 0.4788 - val_accuracy: 0.7780\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4821 - accuracy: 0.7795 - val_loss: 0.4562 - val_accuracy: 0.7900\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4556 - accuracy: 0.7857 - val_loss: 0.4439 - val_accuracy: 0.7880\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4486 - accuracy: 0.8004 - val_loss: 0.4364 - val_accuracy: 0.7960\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4279 - accuracy: 0.8099 - val_loss: 0.4241 - val_accuracy: 0.8100\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4241 - accuracy: 0.8164 - val_loss: 0.4215 - val_accuracy: 0.7950\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4214 - accuracy: 0.8139 - val_loss: 0.4468 - val_accuracy: 0.7930\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4038 - accuracy: 0.8248 - val_loss: 0.4156 - val_accuracy: 0.8100\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.4091 - accuracy: 0.8179 - val_loss: 0.4281 - val_accuracy: 0.7990\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4005 - accuracy: 0.8219 - val_loss: 0.4200 - val_accuracy: 0.8090\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3845 - accuracy: 0.8404 - val_loss: 0.4113 - val_accuracy: 0.8060\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.3820 - accuracy: 0.8409 - val_loss: 0.4200 - val_accuracy: 0.8210\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.3775 - accuracy: 0.8355 - val_loss: 0.4088 - val_accuracy: 0.8160\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3668 - accuracy: 0.8423 - val_loss: 0.3911 - val_accuracy: 0.8230\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3743 - accuracy: 0.8433 - val_loss: 0.3926 - val_accuracy: 0.8100\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3773 - accuracy: 0.8420 - val_loss: 0.3960 - val_accuracy: 0.8150\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3612 - accuracy: 0.8449 - val_loss: 0.3894 - val_accuracy: 0.8170\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3583 - accuracy: 0.8452 - val_loss: 0.3977 - val_accuracy: 0.8130\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3637 - accuracy: 0.8467 - val_loss: 0.4063 - val_accuracy: 0.8200\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3474 - accuracy: 0.8587 - val_loss: 0.4253 - val_accuracy: 0.8220\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3549 - accuracy: 0.8543 - val_loss: 0.4033 - val_accuracy: 0.8160\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3604 - accuracy: 0.8451 - val_loss: 0.4070 - val_accuracy: 0.8220\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3471 - accuracy: 0.8555 - val_loss: 0.4084 - val_accuracy: 0.8240\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.3514 - accuracy: 0.8504 - val_loss: 0.3860 - val_accuracy: 0.8160\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3446 - accuracy: 0.8561 - val_loss: 0.3881 - val_accuracy: 0.8120\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3491 - accuracy: 0.8509 - val_loss: 0.4035 - val_accuracy: 0.8170\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3458 - accuracy: 0.8523 - val_loss: 0.3930 - val_accuracy: 0.8290\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3271 - accuracy: 0.8616 - val_loss: 0.3866 - val_accuracy: 0.8200\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3324 - accuracy: 0.8625 - val_loss: 0.3836 - val_accuracy: 0.8190\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3196 - accuracy: 0.8622 - val_loss: 0.3993 - val_accuracy: 0.8240\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.3301 - accuracy: 0.8642 - val_loss: 0.4106 - val_accuracy: 0.8150\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3377 - accuracy: 0.8572 - val_loss: 0.3919 - val_accuracy: 0.8280\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3347 - accuracy: 0.8589 - val_loss: 0.3902 - val_accuracy: 0.8120\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3225 - accuracy: 0.8655 - val_loss: 0.4017 - val_accuracy: 0.8220\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3167 - accuracy: 0.8677 - val_loss: 0.3968 - val_accuracy: 0.8290\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3164 - accuracy: 0.8633 - val_loss: 0.4106 - val_accuracy: 0.8260\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3270 - accuracy: 0.8626 - val_loss: 0.3865 - val_accuracy: 0.8210\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3140 - accuracy: 0.8669 - val_loss: 0.4023 - val_accuracy: 0.8100\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3028 - accuracy: 0.8727 - val_loss: 0.3985 - val_accuracy: 0.8200\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3225 - accuracy: 0.8647 - val_loss: 0.3846 - val_accuracy: 0.8240\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3084 - accuracy: 0.8716 - val_loss: 0.3943 - val_accuracy: 0.8240\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3217 - accuracy: 0.8650 - val_loss: 0.4050 - val_accuracy: 0.8260\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3058 - accuracy: 0.8738 - val_loss: 0.3964 - val_accuracy: 0.8230\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3071 - accuracy: 0.8662 - val_loss: 0.4250 - val_accuracy: 0.8170\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3031 - accuracy: 0.8732 - val_loss: 0.4078 - val_accuracy: 0.8160\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2965 - accuracy: 0.8783 - val_loss: 0.4017 - val_accuracy: 0.8150\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3013 - accuracy: 0.8764 - val_loss: 0.4425 - val_accuracy: 0.8130\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3141 - accuracy: 0.8714 - val_loss: 0.4478 - val_accuracy: 0.8230\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3140 - accuracy: 0.8670 - val_loss: 0.4215 - val_accuracy: 0.8210\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2977 - accuracy: 0.8776 - val_loss: 0.4185 - val_accuracy: 0.8130\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2970 - accuracy: 0.8735 - val_loss: 0.4120 - val_accuracy: 0.8220\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2922 - accuracy: 0.8799 - val_loss: 0.4093 - val_accuracy: 0.8200\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2941 - accuracy: 0.8785 - val_loss: 0.4059 - val_accuracy: 0.8240\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2825 - accuracy: 0.8818 - val_loss: 0.3990 - val_accuracy: 0.8200\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2923 - accuracy: 0.8754 - val_loss: 0.4264 - val_accuracy: 0.8210\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2763 - accuracy: 0.8876 - val_loss: 0.4137 - val_accuracy: 0.8230\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2874 - accuracy: 0.8808 - val_loss: 0.4365 - val_accuracy: 0.8180\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2717 - accuracy: 0.8900 - val_loss: 0.4242 - val_accuracy: 0.8220\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2958 - accuracy: 0.8790 - val_loss: 0.4249 - val_accuracy: 0.8210\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2883 - accuracy: 0.8748 - val_loss: 0.4207 - val_accuracy: 0.8270\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2820 - accuracy: 0.8817 - val_loss: 0.4369 - val_accuracy: 0.8120\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2766 - accuracy: 0.8871 - val_loss: 0.4455 - val_accuracy: 0.8070\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2897 - accuracy: 0.8766 - val_loss: 0.4282 - val_accuracy: 0.8240\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2731 - accuracy: 0.8843 - val_loss: 0.4418 - val_accuracy: 0.8220\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2704 - accuracy: 0.8879 - val_loss: 0.4555 - val_accuracy: 0.8090\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2831 - accuracy: 0.8856 - val_loss: 0.4368 - val_accuracy: 0.8220\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2624 - accuracy: 0.8956 - val_loss: 0.4457 - val_accuracy: 0.8170\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2741 - accuracy: 0.8873 - val_loss: 0.4498 - val_accuracy: 0.8210\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2689 - accuracy: 0.8863 - val_loss: 0.4509 - val_accuracy: 0.8220\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2685 - accuracy: 0.8880 - val_loss: 0.4345 - val_accuracy: 0.8210\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2694 - accuracy: 0.8871 - val_loss: 0.4510 - val_accuracy: 0.8110\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2559 - accuracy: 0.8960 - val_loss: 0.4581 - val_accuracy: 0.8280\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2684 - accuracy: 0.8884 - val_loss: 0.4574 - val_accuracy: 0.8220\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2649 - accuracy: 0.8908 - val_loss: 0.4546 - val_accuracy: 0.8140\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2651 - accuracy: 0.8906 - val_loss: 0.4603 - val_accuracy: 0.8220\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2505 - accuracy: 0.8995 - val_loss: 0.4694 - val_accuracy: 0.8160\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2595 - accuracy: 0.8941 - val_loss: 0.4897 - val_accuracy: 0.8030\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2403 - accuracy: 0.9049 - val_loss: 0.4624 - val_accuracy: 0.8170\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2585 - accuracy: 0.8944 - val_loss: 0.5001 - val_accuracy: 0.8200\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2504 - accuracy: 0.8967 - val_loss: 0.4696 - val_accuracy: 0.8280\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2684 - accuracy: 0.8937 - val_loss: 0.4675 - val_accuracy: 0.8280\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2525 - accuracy: 0.8970 - val_loss: 0.4856 - val_accuracy: 0.8230\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2590 - accuracy: 0.8933 - val_loss: 0.4866 - val_accuracy: 0.8110\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2488 - accuracy: 0.8983 - val_loss: 0.4877 - val_accuracy: 0.8270\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2366 - accuracy: 0.9027 - val_loss: 0.4894 - val_accuracy: 0.8130\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2413 - accuracy: 0.8990 - val_loss: 0.4941 - val_accuracy: 0.8220\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2449 - accuracy: 0.9021 - val_loss: 0.4858 - val_accuracy: 0.8230\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2519 - accuracy: 0.8977 - val_loss: 0.4825 - val_accuracy: 0.8220\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2421 - accuracy: 0.9027 - val_loss: 0.4915 - val_accuracy: 0.8060\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2372 - accuracy: 0.9078 - val_loss: 0.4623 - val_accuracy: 0.8230\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2394 - accuracy: 0.9035 - val_loss: 0.4828 - val_accuracy: 0.8190\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2355 - accuracy: 0.9051 - val_loss: 0.4784 - val_accuracy: 0.8180\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2297 - accuracy: 0.9114 - val_loss: 0.5029 - val_accuracy: 0.8140\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2334 - accuracy: 0.9068 - val_loss: 0.4887 - val_accuracy: 0.8230\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2325 - accuracy: 0.9065 - val_loss: 0.4895 - val_accuracy: 0.8180\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2385 - accuracy: 0.9094 - val_loss: 0.4753 - val_accuracy: 0.8300\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2280 - accuracy: 0.9073 - val_loss: 0.4960 - val_accuracy: 0.8170\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9996847\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9342868\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
